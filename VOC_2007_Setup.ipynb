{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VOC_2007_Setup.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFDNoThyiw9f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b0a2c5a8-07bb-474e-80a7-88959a49e8f1"
      },
      "source": [
        "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n",
        "!tar -xf VOCtrainval_06-Nov-2007.tar\n",
        "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n",
        "!tar -xf VOCtest_06-Nov-2007.tar\n",
        "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtestnoimgs_06-Nov-2007.tar"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-15 13:41:24--  http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n",
            "Resolving host.robots.ox.ac.uk (host.robots.ox.ac.uk)... 129.67.94.152\n",
            "Connecting to host.robots.ox.ac.uk (host.robots.ox.ac.uk)|129.67.94.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 460032000 (439M) [application/x-tar]\n",
            "Saving to: ‘VOCtrainval_06-Nov-2007.tar’\n",
            "\n",
            "VOCtrainval_06-Nov- 100%[===================>] 438.72M  8.86MB/s    in 52s     \n",
            "\n",
            "2020-05-15 13:42:17 (8.45 MB/s) - ‘VOCtrainval_06-Nov-2007.tar’ saved [460032000/460032000]\n",
            "\n",
            "--2020-05-15 13:42:21--  http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n",
            "Resolving host.robots.ox.ac.uk (host.robots.ox.ac.uk)... 129.67.94.152\n",
            "Connecting to host.robots.ox.ac.uk (host.robots.ox.ac.uk)|129.67.94.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 451020800 (430M) [application/x-tar]\n",
            "Saving to: ‘VOCtest_06-Nov-2007.tar’\n",
            "\n",
            "VOCtest_06-Nov-2007 100%[===================>] 430.13M  8.73MB/s    in 49s     \n",
            "\n",
            "2020-05-15 13:43:11 (8.70 MB/s) - ‘VOCtest_06-Nov-2007.tar’ saved [451020800/451020800]\n",
            "\n",
            "--2020-05-15 13:43:16--  http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtestnoimgs_06-Nov-2007.tar\n",
            "Resolving host.robots.ox.ac.uk (host.robots.ox.ac.uk)... 129.67.94.152\n",
            "Connecting to host.robots.ox.ac.uk (host.robots.ox.ac.uk)|129.67.94.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12492800 (12M) [application/x-tar]\n",
            "Saving to: ‘VOCtestnoimgs_06-Nov-2007.tar’\n",
            "\n",
            "VOCtestnoimgs_06-No 100%[===================>]  11.91M  5.19MB/s    in 2.3s    \n",
            "\n",
            "2020-05-15 13:43:18 (5.19 MB/s) - ‘VOCtestnoimgs_06-Nov-2007.tar’ saved [12492800/12492800]\n",
            "\n",
            "Collecting ray\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/e4/f91074d5faca7532064dd8f01bf3bc6bffaf5cc81b9605c85f8b1bb6c841/ray-0.8.5-cp36-cp36m-manylinux1_x86_64.whl (21.2MB)\n",
            "\u001b[K     |████████████████████████████████| 21.2MB 1.5MB/s \n",
            "\u001b[?25hCollecting msgpack<1.0.0,>=0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/a8/e01fea81691749044a7bfd44536483a296d9c0a7ed4ec8810a229435547c/msgpack-0.6.2-cp36-cp36m-manylinux1_x86_64.whl (249kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 44.1MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: google in /usr/local/lib/python3.6/dist-packages (from ray) (2.0.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from ray) (7.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from ray) (3.0.12)\n",
            "Collecting aiohttp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/39/7eb5f98d24904e0f6d3edb505d4aa60e3ef83c0a58d6fe18244a51757247/aiohttp-3.6.2-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 43.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from ray) (3.10.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from ray) (2.6.0)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.6/dist-packages (from ray) (1.28.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from ray) (3.13)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.6/dist-packages (from ray) (1.18.4)\n",
            "Collecting redis<3.5.0,>=3.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/05/1fc7feedc19c123e7a95cfc9e7892eb6cdd2e5df4e9e8af6384349c1cc3d/redis-3.4.1-py2.py3-none-any.whl (71kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.8MB/s \n",
            "\u001b[?25hCollecting py-spy>=0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/a7/ab45c9ee3c4654edda3efbd6b8e2fa4962226718a7e3e3be6e3926bf3617/py_spy-0.3.3-py2.py3-none-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 40.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from google->ray) (4.6.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray) (19.3.0)\n",
            "Collecting idna-ssl>=1.0; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/46/03/07c4894aae38b0de52b52586b24bf189bb83e4ddabfe2e2c8f2419eec6f4/idna-ssl-1.1.0.tar.gz\n",
            "Requirement already satisfied: typing-extensions>=3.6.5; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray) (3.6.6)\n",
            "Collecting async-timeout<4.0,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Collecting multidict<5.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/95/f50352b5366e7d579e8b99631680a9e32e1b22adfa1629a8f23b1d22d5e2/multidict-4.7.6-cp36-cp36m-manylinux1_x86_64.whl (148kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 48.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4.0,>=2.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray) (3.0.4)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/8f/0209fc5d975f839344c33c822ff2f7ef80f6b1e984673a5a68f960bfa583/yarl-1.4.2-cp36-cp36m-manylinux1_x86_64.whl (252kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 42.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->ray) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->ray) (46.1.3)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.6/dist-packages (from idna-ssl>=1.0; python_version < \"3.7\"->aiohttp->ray) (2.9)\n",
            "Building wheels for collected packages: idna-ssl\n",
            "  Building wheel for idna-ssl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for idna-ssl: filename=idna_ssl-1.1.0-cp36-none-any.whl size=3162 sha256=68cf53a44e409af841430008b72bfb3ffff84ad8fba9781a32231be5c881b4f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/00/b3/32d613e19e08a739751dd6bf998cfed277728f8b2127ad4eb7\n",
            "Successfully built idna-ssl\n",
            "Installing collected packages: msgpack, colorama, idna-ssl, async-timeout, multidict, yarl, aiohttp, redis, py-spy, ray\n",
            "  Found existing installation: msgpack 1.0.0\n",
            "    Uninstalling msgpack-1.0.0:\n",
            "      Successfully uninstalled msgpack-1.0.0\n",
            "Successfully installed aiohttp-3.6.2 async-timeout-3.0.1 colorama-0.4.3 idna-ssl-1.1.0 msgpack-0.6.2 multidict-4.7.6 py-spy-0.3.3 ray-0.8.5 redis-3.4.1 yarl-1.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOBXyY5ajAcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "import io, json, os, ray\n",
        "from xml.etree import ElementTree as ET"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAbYAWJBlSsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A06rjQCFlVBv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "62ba04f5-8f77-4bd3-c727-4151b3ad198b"
      },
      "source": [
        "num_train_shards = 2\n",
        "num_val_shards = 2\n",
        "num_test_shards = 2\n",
        "ray.init()\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-15 13:45:50,680\tINFO resource_spec.py:212 -- Starting Ray with 7.23 GiB memory available for workers and up to 3.62 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
            "2020-05-15 13:45:51,154\tINFO services.py:1170 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBHLiaoflX-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def chunkify(l, n):\n",
        "    size = len(l) // n\n",
        "    start = 0\n",
        "    results = []\n",
        "    for i in range(n - 1):\n",
        "        results.append(l[start:start + size])\n",
        "        start += size\n",
        "    results.append(l[start:])\n",
        "    return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dTBxbFFlcYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _bytes_feature(value):\n",
        "    if isinstance(value, type(tf.constant(0))):\n",
        "        value = value.numpy()\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndaWsLbMlkQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def genreate_tfexample(anno):\n",
        "    with open(anno['filepath'], 'rb') as image_file:\n",
        "        content = image_file.read()\n",
        "    width = anno['width']\n",
        "    height = anno['height']\n",
        "    depth = anno['depth']\n",
        "    if depth != 3:\n",
        "        print('WANRNING: Image {} has depth of {}'.format(\n",
        "            anno['filename'], depth))\n",
        "    class_ids = []\n",
        "    class_texts = []\n",
        "    bbox_xmins = []\n",
        "    bbox_ymins = []\n",
        "    bbox_xmaxs = []\n",
        "    bbox_ymaxs = []\n",
        "    for bbox in anno['bboxes']:\n",
        "        class_ids.append(bbox['class_id'])\n",
        "        class_texts.append(bbox['class_text'].encode())\n",
        "        xmin, ymin, xmax, ymax = bbox['xmin'], bbox['ymin'], bbox[\n",
        "            'xmax'], bbox['ymax']\n",
        "        bbox_xmin, bbox_ymin, bbox_xmax, bbox_ymax = float(\n",
        "            xmin) / width, float(ymin) / height, float(xmax) / width, float(\n",
        "                ymax) / height\n",
        "        assert bbox_xmin <= 1 and bbox_xmin >= 0\n",
        "        assert bbox_ymin <= 1 and bbox_ymin >= 0\n",
        "        assert bbox_xmax <= 1 and bbox_xmax >= 0\n",
        "        assert bbox_ymax <= 1 and bbox_ymax >= 0\n",
        "        bbox_xmins.append(bbox_xmin)\n",
        "        bbox_ymins.append(bbox_ymin)\n",
        "        bbox_xmaxs.append(bbox_xmax)\n",
        "        bbox_ymaxs.append(bbox_ymax)\n",
        "    feature = {\n",
        "        'image/height':\n",
        "        tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n",
        "        'image/width':\n",
        "        tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n",
        "        'image/depth':\n",
        "        tf.train.Feature(int64_list=tf.train.Int64List(value=[depth])),\n",
        "        'image/object/bbox/xmin':\n",
        "        tf.train.Feature(float_list=tf.train.FloatList(value=bbox_xmins)),\n",
        "        'image/object/bbox/ymin':\n",
        "        tf.train.Feature(float_list=tf.train.FloatList(value=bbox_ymins)),\n",
        "        'image/object/bbox/xmax':\n",
        "        tf.train.Feature(float_list=tf.train.FloatList(value=bbox_xmaxs)),\n",
        "        'image/object/bbox/ymax':\n",
        "        tf.train.Feature(float_list=tf.train.FloatList(value=bbox_ymaxs)),\n",
        "        'image/object/class/label':\n",
        "        tf.train.Feature(int64_list=tf.train.Int64List(value=class_ids)),\n",
        "        'image/object/class/text':\n",
        "        tf.train.Feature(bytes_list=tf.train.BytesList(value=class_texts)),\n",
        "        'image/encoded':\n",
        "        _bytes_feature(content),\n",
        "        'image/filename':\n",
        "        _bytes_feature(anno['filename'].encode())\n",
        "    }\n",
        "    return tf.train.Example(features=tf.train.Features(feature=feature))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPReU0bRlqSz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@ray.remote\n",
        "def build_single_tfrecord(chunk, path):\n",
        "    print('start to build tf records for ' + path)\n",
        "\n",
        "    with tf.io.TFRecordWriter(path) as writer:\n",
        "        for anno in chunk:\n",
        "            tf_example = genreate_tfexample(anno)\n",
        "            writer.write(tf_example.SerializeToString())\n",
        "\n",
        "    print('finished building tf records for ' + path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQMMhNMDluBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_tf_records(annotations, total_shards, split):\n",
        "    chunks = chunkify(annotations, total_shards)\n",
        "    futures = [\n",
        "        # train_0001_of_0064.tfrecords\n",
        "        build_single_tfrecord.remote(\n",
        "            chunk, './tfrecords_voc/{}_{}_of_{}.tfrecords'.format(\n",
        "                split,\n",
        "                str(i + 1).zfill(4),\n",
        "                str(total_shards).zfill(4),\n",
        "            )) for i, chunk in enumerate(chunks)\n",
        "    ]\n",
        "    ray.get(futures)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykeiJLFFlws4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_one_xml(xml_file, names_map):\n",
        "    tree = ET.parse(os.path.join('./VOCdevkit/VOC2007/Annotations', xml_file))\n",
        "    root = tree.getroot()\n",
        "    filename = root.find('.//filename').text\n",
        "    filepath = os.path.join('./VOCdevkit/VOC2007/JPEGImages', filename)\n",
        "    objects_els = root.findall('.//object')\n",
        "    size_el = root.find('size')\n",
        "    width = int(size_el.find('width').text)\n",
        "    height = int(size_el.find('height').text)\n",
        "    depth = int(size_el.find('depth').text)\n",
        "\n",
        "    bboxes = []\n",
        "    for obj_el in objects_els:\n",
        "        name_el = obj_el.find('name')\n",
        "        bbox_el = obj_el.find('bndbox')\n",
        "        bboxes.append({\n",
        "            'class_text': name_el.text,\n",
        "            'class_id': names_map[name_el.text],\n",
        "            'xmin': int(bbox_el.find('xmin').text),\n",
        "            'ymin': int(bbox_el.find('ymin').text),\n",
        "            'xmax': int(bbox_el.find('xmax').text),\n",
        "            'ymax': int(bbox_el.find('ymax').text),\n",
        "        })\n",
        "\n",
        "    return {\n",
        "        'filepath': filepath,\n",
        "        'filename': filename,\n",
        "        'width': width,\n",
        "        'height': height,\n",
        "        'depth': depth,\n",
        "        'bboxes': bboxes,\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeHtnQRdl04Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    print('Start to parse annotations.')\n",
        "    if not os.path.exists('./tfrecords_voc'):\n",
        "        os.makedirs('./tfrecords_voc')\n",
        "    train_val_split = {}\n",
        "    with open('./VOCdevkit/VOC2007/ImageSets/Main/train.txt') as train_fp:\n",
        "        lines = train_fp.read().splitlines()\n",
        "        for line in lines:\n",
        "            train_val_split[line] = 'train'\n",
        "    with open('./VOCdevkit/VOC2007/ImageSets/Main/val.txt') as val_fp:\n",
        "        lines = val_fp.read().splitlines()\n",
        "        for line in lines:\n",
        "            train_val_split[line] = 'val'\n",
        "    with open('./VOCdevkit/VOC2007/ImageSets/Main/test.txt') as val_fp:\n",
        "        lines = val_fp.read().splitlines()\n",
        "        for line in lines:\n",
        "            train_val_split[line] = 'test'\n",
        "    names = [\n",
        "             'aeroplane',\n",
        "             'bicycle',\n",
        "             'bird',\n",
        "             'boat',\n",
        "             'bottle',\n",
        "             'bus',\n",
        "             'car',\n",
        "             'cat',\n",
        "             'chair',\n",
        "             'cow',\n",
        "             'diningtable',\n",
        "             'dog',\n",
        "             'horse',\n",
        "             'motorbike',\n",
        "             'person',\n",
        "             'pottedplant',\n",
        "             'sheep',\n",
        "             'sofa',\n",
        "             'train',\n",
        "             'tvmonitor'\n",
        "            ]\n",
        "    names_map = {name: i for i, name in enumerate(names)}\n",
        "    print(names_map)\n",
        "    train_annotations = []\n",
        "    val_annotations = []\n",
        "    test_annotations = []\n",
        "    for xml_file in os.listdir('./VOCdevkit/VOC2007/Annotations'):\n",
        "        image_id = xml_file[:-4]\n",
        "        if train_val_split[image_id] == 'train':\n",
        "            train_annotations.append(parse_one_xml(xml_file, names_map))\n",
        "        elif train_val_split[image_id] == 'val':\n",
        "            val_annotations.append(parse_one_xml(xml_file, names_map))\n",
        "        elif train_val_split[image_id] == 'test':\n",
        "            test_annotations.append(parse_one_xml(xml_file, names_map))\n",
        "        else:\n",
        "            print('WARNING: Unwanted image id {}'.format(image_id))\n",
        "    print('Start to build TF Records.')\n",
        "    build_tf_records(train_annotations, num_train_shards, 'train')\n",
        "    build_tf_records(val_annotations, num_val_shards, 'val')\n",
        "    build_tf_records(test_annotations, num_test_shards, 'test')\n",
        "    print('Successfully wrote {} annotations to TF Records.'.format(\n",
        "        len(train_annotations) + len(val_annotations) + len(test_annotations)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gjccj2Sl9A5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "c34cb6ee-1ff3-411b-86d5-ac02d014128a"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start to parse annotations.\n",
            "{'aeroplane': 0, 'bicycle': 1, 'bird': 2, 'boat': 3, 'bottle': 4, 'bus': 5, 'car': 6, 'cat': 7, 'chair': 8, 'cow': 9, 'diningtable': 10, 'dog': 11, 'horse': 12, 'motorbike': 13, 'person': 14, 'pottedplant': 15, 'sheep': 16, 'sofa': 17, 'train': 18, 'tvmonitor': 19}\n",
            "Start to build TF Records.\n",
            "\u001b[2m\u001b[36m(pid=230)\u001b[0m start to build tf records for ./tfrecords_voc/train_0001_of_0002.tfrecords\n",
            "\u001b[2m\u001b[36m(pid=229)\u001b[0m start to build tf records for ./tfrecords_voc/train_0002_of_0002.tfrecords\n",
            "\u001b[2m\u001b[36m(pid=229)\u001b[0m finished building tf records for ./tfrecords_voc/train_0002_of_0002.tfrecords\n",
            "\u001b[2m\u001b[36m(pid=230)\u001b[0m finished building tf records for ./tfrecords_voc/train_0001_of_0002.tfrecords\n",
            "\u001b[2m\u001b[36m(pid=230)\u001b[0m start to build tf records for ./tfrecords_voc/val_0001_of_0002.tfrecords\n",
            "\u001b[2m\u001b[36m(pid=229)\u001b[0m start to build tf records for ./tfrecords_voc/val_0002_of_0002.tfrecords\n",
            "\u001b[2m\u001b[36m(pid=230)\u001b[0m finished building tf records for ./tfrecords_voc/val_0001_of_0002.tfrecords\n",
            "\u001b[2m\u001b[36m(pid=229)\u001b[0m finished building tf records for ./tfrecords_voc/val_0002_of_0002.tfrecords\n",
            "\u001b[2m\u001b[36m(pid=230)\u001b[0m start to build tf records for ./tfrecords_voc/test_0002_of_0002.tfrecords\n",
            "\u001b[2m\u001b[36m(pid=229)\u001b[0m start to build tf records for ./tfrecords_voc/test_0001_of_0002.tfrecords\n",
            "\u001b[2m\u001b[36m(pid=229)\u001b[0m finished building tf records for ./tfrecords_voc/test_0001_of_0002.tfrecords\n",
            "Successfully wrote 9963 annotations to TF Records.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEyw9m93l_Km",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}