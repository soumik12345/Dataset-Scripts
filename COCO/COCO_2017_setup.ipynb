{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COCO_2017_setup.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6CvXaR57e8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir val2017\n",
        "!mkdir train2017\n",
        "!mkdir test2017\n",
        "!gsutil -m rsync gs://images.cocodataset.org/val2017 val2017\n",
        "!gsutil -m rsync gs://images.cocodataset.org/train2017 train2017\n",
        "!gsutil -m rsync gs://images.cocodataset.org/test2017 test2017\n",
        "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
        "!unzip annotations_trainval2017.zip\n",
        "!pip install ray"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuVQZeD65A1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "import csv, io, json, os, ray"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTJz-k1o5JP-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxAiflqI6CQJ",
        "colab_type": "code",
        "outputId": "3a2f53a2-f945-413a-d103-8a0d32f49204",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "num_train_shards = 64\n",
        "num_val_shards = 8\n",
        "ray.init()\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-15 15:16:15,235\tINFO resource_spec.py:212 -- Starting Ray with 7.23 GiB memory available for workers and up to 3.62 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
            "2020-05-15 15:16:15,688\tINFO services.py:1170 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZWH74pX6EUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def chunkify(l, n):\n",
        "    size = len(l) // n\n",
        "    start = 0\n",
        "    results = []\n",
        "    for i in range(n - 1):\n",
        "        results.append(l[start:start + size])\n",
        "        start += size\n",
        "    results.append(l[start:])\n",
        "    return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax7qXV0o6G__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _bytes_feature(value):\n",
        "    if isinstance(value, type(tf.constant(0))):\n",
        "        value = value.numpy()\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0t9CA9Y6LHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def genreate_tfexample(anno_list):\n",
        "    filename = anno_list[0]['filename']\n",
        "    with open(filename, 'rb') as image_file:\n",
        "        content = image_file.read()\n",
        "    image = Image.open(filename)\n",
        "    if image.format != 'JPEG' or image.mode != 'RGB':\n",
        "        image_rgb = image.convert('RGB')\n",
        "        with io.BytesIO() as output:\n",
        "            image_rgb.save(output, format=\"JPEG\", quality=95)\n",
        "            content = output.getvalue()\n",
        "    width, height = image.size\n",
        "    depth = 3\n",
        "    class_ids = []\n",
        "    class_texts = []\n",
        "    bbox_xmins = []\n",
        "    bbox_ymins = []\n",
        "    bbox_xmaxs = []\n",
        "    bbox_ymaxs = []\n",
        "    for anno in anno_list:\n",
        "        class_ids.append(anno['class_id'])\n",
        "        class_texts.append(anno['class_text'].encode())\n",
        "        xmin, ymin, xmax, ymax = anno['xmin'], anno['ymin'], anno[\n",
        "            'xmax'], anno['ymax']\n",
        "        bbox_xmin, bbox_ymin, bbox_xmax, bbox_ymax = float(\n",
        "            xmin) / width, float(ymin) / height, float(xmax) / width, float(\n",
        "                ymax) / height\n",
        "        assert bbox_xmin <= 1 and bbox_xmin >= 0\n",
        "        assert bbox_ymin <= 1 and bbox_ymin >= 0\n",
        "        assert bbox_xmax <= 1 and bbox_xmax >= 0\n",
        "        assert bbox_ymax <= 1 and bbox_ymax >= 0\n",
        "        bbox_xmins.append(bbox_xmin)\n",
        "        bbox_ymins.append(bbox_ymin)\n",
        "        bbox_xmaxs.append(bbox_xmax)\n",
        "        bbox_ymaxs.append(bbox_ymax)\n",
        "    feature = {\n",
        "        'image/height':\n",
        "        tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n",
        "        'image/width':\n",
        "        tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n",
        "        'image/depth':\n",
        "        tf.train.Feature(int64_list=tf.train.Int64List(value=[depth])),\n",
        "        'image/object/bbox/xmin':\n",
        "        tf.train.Feature(float_list=tf.train.FloatList(value=bbox_xmins)),\n",
        "        'image/object/bbox/ymin':\n",
        "        tf.train.Feature(float_list=tf.train.FloatList(value=bbox_ymins)),\n",
        "        'image/object/bbox/xmax':\n",
        "        tf.train.Feature(float_list=tf.train.FloatList(value=bbox_xmaxs)),\n",
        "        'image/object/bbox/ymax':\n",
        "        tf.train.Feature(float_list=tf.train.FloatList(value=bbox_ymaxs)),\n",
        "        'image/object/class/label':\n",
        "        tf.train.Feature(int64_list=tf.train.Int64List(value=class_ids)),\n",
        "        'image/object/class/text':\n",
        "        tf.train.Feature(bytes_list=tf.train.BytesList(value=class_texts)),\n",
        "        'image/encoded':\n",
        "        _bytes_feature(content),\n",
        "        'image/filename':\n",
        "        _bytes_feature(os.path.basename(filename).encode())\n",
        "    }\n",
        "    return tf.train.Example(features=tf.train.Features(feature=feature))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZgUhQ7m6Oc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@ray.remote\n",
        "def build_single_tfrecord(chunk, path):\n",
        "    print('start to build tf records for ' + path)\n",
        "    with tf.io.TFRecordWriter(path) as writer:\n",
        "        for anno_list in chunk:\n",
        "            tf_example = genreate_tfexample(anno_list)\n",
        "            writer.write(tf_example.SerializeToString())\n",
        "    print('finished building tf records for ' + path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKMSkB796V3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_tf_records(annotations, total_shards, split):\n",
        "    annotations_by_image = {}\n",
        "    for annotation in annotations:\n",
        "        if annotation['filename'] in annotations_by_image:\n",
        "            annotations_by_image[annotation['filename']].append(annotation)\n",
        "        else:\n",
        "            annotations_by_image[annotation['filename']] = [annotation]\n",
        "    chunks = chunkify(list(annotations_by_image.values()), total_shards)\n",
        "    futures = [\n",
        "        # train_0001_of_0064.tfrecords\n",
        "        build_single_tfrecord.remote(\n",
        "            chunk, './tfrecords/{}_{}_of_{}.tfrecords'.format(\n",
        "                split,\n",
        "                str(i + 1).zfill(4),\n",
        "                str(total_shards).zfill(4),\n",
        "            )) for i, chunk in enumerate(chunks)\n",
        "    ]\n",
        "    ray.get(futures)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPpUaXUT6Y2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_one_annotation(anno, categories, dir):\n",
        "    category_id = int(anno['category_id'])\n",
        "    category = categories[category_id]\n",
        "    class_id = category[0]\n",
        "    if class_id < 0:\n",
        "        print('ALERT: class is {} is invalid'.format(class_id))\n",
        "    class_text = category[1]\n",
        "    bbox = anno['bbox']\n",
        "    filename = '{}/{}.jpg'.format(dir, str(anno['image_id']).rjust(12, '0'))\n",
        "    annotation = {\n",
        "        'filename': filename,\n",
        "        'class_id': class_id,\n",
        "        'class_text': class_text,\n",
        "        'xmin': float(bbox[0]),\n",
        "        'ymin': float(bbox[1]),\n",
        "        'xmax': float(bbox[0]) + float(bbox[2]),\n",
        "        'ymax': float(bbox[1]) + float(bbox[3]),\n",
        "    }\n",
        "    return annotation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ctvNjHn6esw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Start to parse annotations.')\n",
        "if not os.path.exists('./tfrecords'):\n",
        "    os.makedirs('./tfrecords')\n",
        "with open('./annotations/instances_train2017.json') as train_json:\n",
        "    train_annos = json.load(train_json)\n",
        "    train_categories = {\n",
        "        category['id']: (i, category['name'])\n",
        "        for i, category in enumerate(train_annos['categories'])\n",
        "    }\n",
        "    print(train_categories)\n",
        "    train_annotations = [\n",
        "        parse_one_annotation(anno, train_categories, './train2017')\n",
        "        for anno in train_annos['annotations']\n",
        "    ]\n",
        "    del (train_annos)\n",
        "with open('./annotations/instances_val2017.json') as val_json:\n",
        "    val_annos = json.load(val_json)\n",
        "    val_categories = {\n",
        "        category['id']: (i, category['name'])\n",
        "        for i, category in enumerate(val_annos['categories'])\n",
        "    }\n",
        "    print(val_categories)\n",
        "    val_annotations = [\n",
        "        parse_one_annotation(anno, val_categories, './val2017')\n",
        "        for anno in val_annos['annotations']\n",
        "    ]\n",
        "    del (val_annos)\n",
        "print('Start to build TF Records.')\n",
        "build_tf_records(train_annotations, num_train_shards, 'train')\n",
        "build_tf_records(val_annotations, num_val_shards, 'val')\n",
        "print('Successfully wrote {} annotations to TF Records.'.format(\n",
        "    len(train_annotations) + len(val_annotations)))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}